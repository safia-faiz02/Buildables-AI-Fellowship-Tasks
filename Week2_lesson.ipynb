{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf6da588",
      "metadata": {
        "id": "bf6da588"
      },
      "source": [
        "# **Buckle Up ! We are starting our week 2 roller coaster**\n",
        "\n",
        "In our first week we covered some theoritical concepts and completed our setup so its time we start building!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6b55c5",
      "metadata": {
        "id": "ca6b55c5"
      },
      "source": [
        "## üìì**Conversational AI Concepts & Model Pipelines**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b7ace2",
      "metadata": {
        "id": "f1b7ace2"
      },
      "source": [
        "üéØ By the end of this week, you will:\n",
        "\n",
        "- Understand LLMs, STT, TTS models and their roles.\n",
        "\n",
        "- Know how to connect to LLMs with APIs (Groq as example).\n",
        "\n",
        "- Use Python (requests + JSON) for API interaction.\n",
        "\n",
        "- Start building a basic chatbot with memory and preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e3c5144",
      "metadata": {
        "id": "8e3c5144"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Large Language Models (LLMs) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03968dc4",
      "metadata": {
        "id": "03968dc4"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 1**: What is an LLM?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd894fc",
      "metadata": {
        "id": "9dd894fc"
      },
      "source": [
        "üëâ It‚Äôs like a super-smart text predictor that can read, understand, and generate human-like sentences.\n",
        "\n",
        "You give it some words ‚Üí it guesses the next words in a way that makes sense.\n",
        "\n",
        "For example:\n",
        "\n",
        "1) You ask a question ‚Üí it gives you an answer.\n",
        "\n",
        "2) You write a sentence ‚Üí it can complete it.\n",
        "\n",
        "3) You give it a topic ‚Üí it can write an essay, code, or even a story.\n",
        "\n",
        "So, its a type of AI trained on huge amounts of text data to generate or understand text.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77076ddc",
      "metadata": {
        "id": "77076ddc"
      },
      "source": [
        "### Types of LLMs\n",
        "\n",
        "1. Encoder-only models (e.g., BERT)\n",
        "\n",
        "    - Best for understanding text (classification, sentiment analysis, embeddings).\n",
        "\n",
        "    - ‚ùå Not good at generating text.\n",
        "\n",
        "2. Decoder-only models (e.g., GPT, LLaMA, Mistral)\n",
        "\n",
        "    - Best for text generation (chatbots, writing, summarization).\n",
        "\n",
        "    - What we use in chatbots.\n",
        "\n",
        "3. Encoder-decoder models (e.g., T5, BART)\n",
        "\n",
        "    - Good at transforming text (translation, summarization, Q&A)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339099fe",
      "metadata": {
        "id": "339099fe"
      },
      "source": [
        "### Must-Knows about LLMs\n",
        "\n",
        "- They don‚Äôt ‚Äúthink‚Äù like humans ‚Üí They predict text based on training.\n",
        "\n",
        "- Garbage in ‚Üí garbage out: Poor prompts = poor answers.\n",
        "\n",
        "- Token limits: Models can only ‚Äúsee‚Äù a certain number of words at a time.\n",
        "\n",
        "- Biases: Trained on internet text ‚Üí may reflect biases/errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1b2dd4",
      "metadata": {
        "id": "8b1b2dd4"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7753565a",
      "metadata": {
        "id": "7753565a"
      },
      "source": [
        "1. Why might a chatbot built on BERT (encoder-only) struggle to answer open-ended questions?\n",
        "\n",
        "- Answer üëâ Encoder-only models are best for text understanding only, not text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5feffca",
      "metadata": {
        "id": "a5feffca"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Speech-to-Text (STT) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9393abf7",
      "metadata": {
        "id": "9393abf7"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 2**: What is STT?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f54ac00",
      "metadata": {
        "id": "3f54ac00"
      },
      "source": [
        "üëâ listens to your voice and turns it into written text.\n",
        "\n",
        "- Converts **audio ‚Üí text**.\n",
        "- Enables voice input for conversational AI.\n",
        "- Think of it as the **ears** of the chatbot.\n",
        "\n",
        "**Popular STT Models**:\n",
        "\n",
        "1) **Whisper (OpenAI)** ‚Äì strong at multilingual speech recognition.\n",
        "2) **Google Speech-to-Text API** ‚Äì widely used, real-time transcription.\n",
        "3) **Vosk** ‚Äì lightweight, offline speech recognition.\n",
        "\n",
        "**Common Usages**\n",
        "\n",
        "1) Voice assistants (Alexa, Siri, Google Assistant).\n",
        "2) Automated captions in meetings or lectures.\n",
        "3) Voice-enabled customer support.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc99714c",
      "metadata": {
        "id": "cc99714c"
      },
      "source": [
        "### Must-Knows about STT\n",
        "\n",
        "- Accuracy depends on **noise, accents, clarity of speech**.\n",
        "\n",
        "- Some models need **internet connection** (API-based), others run **offline**.\n",
        "\n",
        "- Preprocessing audio (noise reduction) improves results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec23bf9a",
      "metadata": {
        "id": "ec23bf9a"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407d8a82",
      "metadata": {
        "id": "407d8a82"
      },
      "source": [
        "2. Why do you think meeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once?\n",
        "\n",
        "- Answer üëâ It struggles because accuracy of the transcription depends on clarity of speech and also on internet connection sometimes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2959a81",
      "metadata": {
        "id": "f2959a81"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Text-to-Speech (TTS) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6650b62d",
      "metadata": {
        "id": "6650b62d"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 3**: What is TTS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_KDyJ4VZe51"
      },
      "source": [
        "üëâ takes written text and speaks it out loud in a human-like voice.\n",
        "\n",
        "- Converts **text ‚Üí audio (speech)**.\n",
        "- Think of it as the **mouth** of the chatbot.\n",
        "- Makes AI ‚Äúspeak‚Äù naturally.\n",
        "\n",
        "**Popular TTS Models**:\n",
        "\n",
        "1) **Google TTS** ‚Äì supports many languages and voices.\n",
        "2) **Amazon Polly** ‚Äì lifelike voice synthesis with customization.\n",
        "3) **ElevenLabs** ‚Äì cutting-edge, realistic voice cloning.\n",
        "\n",
        "**Common Usages**\n",
        "\n",
        "1) Screen readers for visually impaired users.\n",
        "2) AI chatbots with voice output.\n",
        "3) Audiobooks or podcast generation.\n",
        "\n",
        "---"
      ],
      "id": "b_KDyJ4VZe51"
    },
    {
      "cell_type": "markdown",
      "id": "cfdb2471",
      "metadata": {
        "id": "cfdb2471"
      },
      "source": [
        "### Must-Knows about TTS\n",
        "\n",
        "- Some voices sound robotic; others use **neural TTS** for natural tones.\n",
        "\n",
        "- Latency matters ‚Üí If too slow, conversation feels unnatural.\n",
        "\n",
        "- Some TTS services allow **custom voices**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee49cb51",
      "metadata": {
        "id": "ee49cb51"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8f3eb2",
      "metadata": {
        "id": "ee8f3eb2"
      },
      "source": [
        "3. If you were designing a voice-based AI tutor, what qualities would you want in its TTS voice (tone, speed, clarity, etc.)?\n",
        "\n",
        "- Answer üëâ I would want clarity in its voice the most, and then maybe the tone to be a little softer and natural."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8042c582",
      "metadata": {
        "id": "8042c582"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Using APIs for LLMs with Groq üåü"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tjq2LdTaOpD",
        "outputId": "0e8b9a90-eb6c-4f81-ece7-33ffe494ee10"
      },
      "id": "5Tjq2LdTaOpD",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/131.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7889d8ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7889d8ee",
        "outputId": "f16170a7-546b-4e52-c3a1-bb13cb768c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversational AI, also known as conversational systems or conversational interfaces, refers to technology that enables computers to understand and respond to natural language inputs from humans, creating a conversation-like experience.\n",
            "\n",
            "Conversational AI uses various techniques from natural language processing (NLP), machine learning (ML), and human-computer interaction (HCI) to process and generate human-like responses. This technology can be used in various applications, such as:\n",
            "\n",
            "1. Chatbots: Automated customer support systems that interact with users through text or voice.\n",
            "2. Virtual Assistants: AI-powered assistants like Siri, Google Assistant, or Alexa that can answer questions, provide information, and perform tasks.\n",
            "3. Voice Assistants: AI-powered systems that use voice inputs to perform tasks, such as Google Duplex.\n",
            "4. Virtual Customer Service Representatives (VCSRs): AI-powered agents that interact with customers to resolve issues or answer questions.\n",
            "5. Live Chat Systems: AI-powered systems that enable real-time text-based conversations between users and support agents.\n",
            "\n",
            "Conversational AI is designed to simulate human-like conversation, using context, tone, and emotion to create a more natural and engaging user experience. However, it's essential to acknowledge that conversational AI systems are not yet perfect and may struggle with ambiguity, nuance, and complex topics.\n",
            "\n",
            "What would you like to know more about conversational AI?\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello! What is conversational AI?\"}]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56c20eb",
      "metadata": {
        "id": "a56c20eb"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Assignments üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bcc2ce6",
      "metadata": {
        "id": "2bcc2ce6"
      },
      "source": [
        "### üìù Assignment 1: LLM Understanding (‚òëÔ∏è)\n",
        "\n",
        "* Write a short note (3‚Äì4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
        "* Give one example usage of each.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder-only models are best for understanding text, like BERT. Decoder-only models are best for text generation, like ChatGPT. And lastly, Encoder-Decoder models are robust text transformers, like BART."
      ],
      "metadata": {
        "id": "rMd6ASkreiNO"
      },
      "id": "rMd6ASkreiNO"
    },
    {
      "cell_type": "markdown",
      "id": "370084b8",
      "metadata": {
        "id": "370084b8"
      },
      "source": [
        "### üìù Assignment 2: STT/TTS Exploration (‚òëÔ∏è)\n",
        "\n",
        "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
        "* Write down:\n",
        "\n",
        "  * What it does.\n",
        "  * One possible application."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speech-to-Text (STT) Model: DeepSpeech (by Mozilla)\n",
        "\n",
        "* What it does: Converts spoken language into written text using a deep learning model trained on large speech datasets.\n",
        "\n",
        "* Application: Can be used for creating real-time transcription tools for online meetings.\n",
        "\n",
        "Text-to-Speech (TTS) Model: FastSpeech 2 (by Microsoft Research)\n",
        "\n",
        "* What it does: A non-autoregressive TTS model that converts text into high-quality, natural-sounding speech quickly.\n",
        "\n",
        "* Application: Useful for real-time applications like screen readers for visually impaired users."
      ],
      "metadata": {
        "id": "ZWcOgCGqqa8N"
      },
      "id": "ZWcOgCGqqa8N"
    },
    {
      "cell_type": "markdown",
      "id": "84824b65",
      "metadata": {
        "id": "84824b65"
      },
      "source": [
        "### üìù Assignment 3: Build a Chatbot with Memory (‚òëÔ∏è)\n",
        "\n",
        "* Write a Python program that:\n",
        "\n",
        "  * Takes user input in a loop.\n",
        "  * Sends it to Groq API.\n",
        "  * Stores the last 5 messages in memory.\n",
        "  * Ends when user types `\"quit\"`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "# Initialize client\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "# Store last 5 exchanges (user + bot)\n",
        "conversation = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == \"quit\":\n",
        "        print(\"Ending chat...\")\n",
        "        break\n",
        "\n",
        "    # Add user message\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Keep only last 5 exchanges (10 messages: 5 user + 5 bot)\n",
        "    if len(conversation) > 10:\n",
        "        conversation = conversation[-10:]\n",
        "\n",
        "    # Send to Groq API\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=conversation\n",
        "    )\n",
        "\n",
        "    bot_reply = response.choices[0].message.content\n",
        "    print(\"Bot:\", bot_reply)\n",
        "\n",
        "    # Add bot reply\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "\n",
        "    # Again, trim history\n",
        "    if len(conversation) > 10:\n",
        "        conversation = conversation[-10:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwMeObWY8SQl",
        "outputId": "9108a1cb-a5d5-444e-e874-62f0563a2d16"
      },
      "id": "gwMeObWY8SQl",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: give me short answers only. what do you think is pakistan\n",
            "Bot: Pakistan is a country located in South Asia, situated east of Iran and west of India.\n",
            "You: what about india\n",
            "Bot: India is a country in South Asia, known for being the world's largest democracy, diverse culture, and vibrant cities.\n",
            "You: and saudi arabia\n",
            "Bot: Saudi Arabia is a Middle Eastern country, home to Islam's holiest site, the holy cities of Mecca and Medina, and a major oil producer.\n",
            "You: and nigeria\n",
            "Bot: Nigeria is a West African country, known for its rich oil reserves, diverse cultures, and vibrant music scene, especially Afrobeats.\n",
            "You: and turkey\n",
            "Bot: Turkey is a Middle Eastern and Mediterranean country, bridging Europe and Asia, with a mix of Islamic and secular culture.\n",
            "You: and turkmenistan\n",
            "Bot: Turkmenistan is a Central Asian country and one of the world's most isolated nations, with a unique blend of Turkic and Soviet influences, rich oil reserves, and a strict authoritarian government.\n",
            "You: and afghanistan\n",
            "Bot: Afghanistan is a Central Asian country with a turbulent history, home to ancient cultures, the world's second-highest mountain range, and a strategically important location, but also marked by ongoing conflict, poverty, and human rights challenges.\n",
            "You: how many countries did i ask u about\n",
            "Bot: You asked me about 5 countries:\n",
            "\n",
            "1. Saudi Arabia\n",
            "2. Nigeria\n",
            "3. Turkey\n",
            "4. Turkmenistan\n",
            "5. Afghanistan\n",
            "You: quit\n",
            "Ending chat...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aef3132",
      "metadata": {
        "id": "1aef3132"
      },
      "source": [
        "### üìù Assignment 4: Preprocessing Function (‚òëÔ∏è)\n",
        "\n",
        "* Write a function to clean user input:\n",
        "\n",
        "  * Lowercase text.\n",
        "  * Remove punctuation.\n",
        "  * Strip extra spaces.\n",
        "\n",
        "Test with: `\"  HELLo!!!  How ARE you?? \"`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Strip extra spaces\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "# Test\n",
        "sample = \"  HELLo!!!  How ARE you?? \"\n",
        "print(clean_text(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz1wFLDxEJvz",
        "outputId": "44e4d00c-bc15-47c3-cf19-f3ae92c16bc4"
      },
      "id": "pz1wFLDxEJvz",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello how are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53027998",
      "metadata": {
        "id": "53027998"
      },
      "source": [
        "### üìù Assignment 5: Text Preprocessing (‚òëÔ∏è)\n",
        "\n",
        "* Write a function that:\n",
        "\n",
        "    * Converts text to lowercase.\n",
        "    * Removes punctuation & numbers.\n",
        "    * Removes stopwords (`the, is, and...`).\n",
        "    * Applies stemming or lemmatization.\n",
        "    * Removes words shorter than 3 characters.\n",
        "    * Keeps only nouns, verbs, and adjectives (using POS tagging)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English pipeline (small model is enough)\n",
        "# Run this in terminal once if not installed:  python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text_spacy(text: str) -> str:\n",
        "    # Process text with spaCy\n",
        "    doc = nlp(text.lower())  # lowercase automatically\n",
        "\n",
        "    processed = []\n",
        "    for token in doc:\n",
        "        # Remove stopwords, punctuation, numbers, and short words (<3 chars)\n",
        "        if (not token.is_stop\n",
        "            and not token.is_punct\n",
        "            and not token.like_num\n",
        "            and len(token.lemma_) >= 3):\n",
        "\n",
        "            # Keep only nouns, verbs, adjectives\n",
        "            if token.pos_ in {\"NOUN\", \"VERB\", \"ADJ\"}:\n",
        "                processed.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(processed)\n",
        "\n",
        "\n",
        "# ---------- Test ----------\n",
        "sample = \"The cats are running quickly in the 2025 streets, and they looked very happy!\"\n",
        "print(preprocess_text_spacy(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpqFuLAoKtSJ",
        "outputId": "2ca27aa7-4de4-4043-d321-b930193b7711"
      },
      "id": "qpqFuLAoKtSJ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat run street look happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb68c035",
      "metadata": {
        "id": "bb68c035"
      },
      "source": [
        "### üìù Assignment 6: Reflection (‚òëÔ∏è)\n",
        "\n",
        "* Answer in 2‚Äì3 sentences:\n",
        "\n",
        "    * Why is context memory important in chatbots?\n",
        "\n",
        "    * ANS: It's important to remember the context of the conversation, so that further down the line the conversation you've with your chatbot remains personalized and effective and you won't have to remind it again and again about what you were just talking about. Kills the purpose of chatbots if there's no memory involved.\n",
        "    * Why should beginners always check **API limits and pricing**?\n",
        "    * ANS: If you don't check the pricing it can cost you more than you expected it to cost you, and checking limits is necessary as well like how many times can you use the model via the API key, or else you'll bottleneck the limit which may result in losing access to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b787de4",
      "metadata": {
        "id": "4b787de4"
      },
      "source": [
        "---\n",
        "\n",
        "### **Hints:**\n",
        "\n",
        "1) Stemming:\n",
        "    - Cuts off word endings to get the ‚Äúroot.‚Äù\n",
        "    - Very mechanical ‚Üí may produce non-real words.\n",
        "    - Example:\n",
        "        - \"studies\" ‚Üí \"studi\"\n",
        "        - \"running\" ‚Üí \"run\"\n",
        "\n",
        "2) Lemmatization:\n",
        "    - Smarter ‚Üí uses vocabulary + grammar rules.\n",
        "    - Always gives a real word (the **lemma**).\n",
        "    - Example:\n",
        "        - \"studies\" ‚Üí \"study\"\n",
        "        - \"running\" ‚Üí \"run\"\n",
        "\n",
        "3) Part-of-Speech (POS) tagging means labeling each word in a sentence with its grammatical role ‚Äî like **noun, verb, adjective, adverb, pronoun, etc.**\n",
        "\n",
        "    - Example:\n",
        "        - Sentence ‚Üí *‚ÄúThe cat is sleeping on the mat.‚Äù*\n",
        "\n",
        "    - POS tags ‚Üí\n",
        "        - The ‚Üí Determiner (DT)\n",
        "        - cat ‚Üí Noun (NN)\n",
        "        - is ‚Üí Verb (VBZ)\n",
        "        - sleeping ‚Üí Verb (VBG)\n",
        "        - on ‚Üí Preposition (IN)\n",
        "        - the ‚Üí Determiner (DT)\n",
        "        - mat ‚Üí Noun (NN)\n",
        "\n",
        "    - **In short:** POS tagging helps machines understand **how words function in a sentence**, which is useful in NLP tasks like machine translation, text classification, and question answering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cec98bb",
      "metadata": {
        "id": "3cec98bb"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ Recap\n",
        "\n",
        "This week you learned:\n",
        "\n",
        "* **LLMs**: Types, uses, must-knows.\n",
        "* **STT & TTS**: How they connect with LLMs.\n",
        "* **APIs**: Connecting to LLMs with Groq.\n",
        "* Built your first chatbot foundation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}